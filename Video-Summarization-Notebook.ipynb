{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import numpy as np                  #For arryas\n",
    "import json                         #For JSON data\n",
    "import os                           #For OS dependent functionalities like making directories\n",
    "from tqdm import tqdm, trange       #For progress bars\n",
    "import h5py                         #For working with hash files\n",
    "import csv                          #To read and write tabular data in CSV format\n",
    "import cv2                          #For importing opencv-python, a great tool for image processing and performing computer vision tasks\n",
    "import matplotlib.pyplot as plt     #For data visualisation\n",
    "import seaborn as sns               #For data visualisation\n",
    "import mat73                        #To load MATLAB 7.3 HDF5 files into a Python dictionary\n",
    "import tensorflow as tf             #For training machine learning models \n",
    "import tensorflow.keras as Keras    #For training machine learning models \n",
    "from tensorflow.keras.models import Sequential                                                  #A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, TimeDistributed, Concatenate    #Other layers of the model\n",
    "from tensorflow.keras.layers import Attention                                                   #Other layers of the model\n",
    "from tensorflow.keras import Input, Model                                                       #Other layers of the model                                                \n",
    "from sklearn.model_selection import train_test_split                                            #Splitting training and testing dataset\n",
    "from prettytable import PrettyTable                                                             #Formatting the table\n",
    "import evals                                                                                    #For Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Data generators:\n",
    "Even the most state-of-the-art configuration may not have enough memory space to process extremely \n",
    "huge datasets the way we used to do it. That is why we need data generators to generate the dataset \n",
    "on multiple cores in real time and feed it right away to the deep learning model efficiently.\n",
    "'''\n",
    "class DataGenerator(Keras.utils.Sequence):\n",
    "\n",
    "    '''\n",
    "    This is the initialization function of the class. We make the latter inherit the properties \n",
    "    of keras.utils.Sequence so that we can leverage several functionalities.\n",
    "\n",
    "    We put as arguments relevant information about the data, such as dimension sizes, \n",
    "    batch size, or decide whether we want to shuffle our data at generation.\n",
    "    Here, the batch size is set to 5 and shuffle is set to false, which means\n",
    "    we will not get a new order of exploration at each pass.\n",
    "    '''\n",
    "    def __init__(self,dataset,batch_size=5,shuffle=False):\n",
    "\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()                 #The method on_epoch_end is triggered once at the very beginning and once at the end of each epoch\n",
    "\n",
    "\n",
    "    '''\n",
    "    This function denotes the number of batches per epoch.\n",
    "    A common practice is to set this value to [# of samples / batch-size ]\n",
    "    so that the model sees the training samples at most once per epoch.\n",
    "    '''\n",
    "    def __len__(self):\n",
    "\n",
    "        return int(np.floor(len(self.dataset)/self.batch_size))\n",
    "\n",
    "    '''\n",
    "    Now, when the batch corresponding to a given index is called, the generator \n",
    "    executes the __getitem__ method to generate one batch of data.\n",
    "    '''\n",
    "    def __getitem__(self,index):\n",
    "\n",
    "        indexes = self.indices[index * self.batch_size : (index+1) * self.batch_size]   # Generate indexes of the batch\n",
    "        feature, label = self.__data_generation(indexes)                                # Generate data\n",
    "\n",
    "        return feature, label\n",
    "\n",
    "    '''\n",
    "    Another method that is core to the generation process is the one that \n",
    "    achieves the most crucial job: producing batches of data. The private method \n",
    "    in charge of this task is called __data_generation and takes as argument the \n",
    "    list of IDs of the target batch.\n",
    "    '''\n",
    "    def __data_generation(self,indexes):\n",
    "\n",
    "        # Initialization\n",
    "        feature = np.empty((self.batch_size,320,1024))\n",
    "        label = np.empty((self.batch_size,320,1))\n",
    "\n",
    "        # Generate data\n",
    "        for i in range(len(indexes)):\n",
    "            feature[i,] = np.array(self.dataset[indexes[i]][0])                 # Store sample\n",
    "            label[i,] = np.array(self.dataset[indexes[i]][1]).reshape(-1,1)     # Store class\n",
    "\n",
    "        return feature,label\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "\n",
    "        #Updates indexes after each epochs\n",
    "        self.indices = np.arange(len(self.dataset))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "'''\n",
    "There is a wide range of possible file types which you can use to store data. HDF5 is one example.\n",
    "HDF5 has some advantages over these data types. They other types are often slower and less compatible than HDF5 files.\n",
    "\n",
    "An HDF5 based model is not too different compared to any other Keras model. \n",
    "In fact, the only differences are present at the start - namely, an extra import as well as \n",
    "a different way of loading the data. \n",
    "\n",
    "The following code uses h5py to load the training and testing data. From the HDF5 files, we retrieve the feature and label datasets.\n",
    "'''\n",
    "class DatasetMaker(object):\n",
    "\n",
    "    def __init__(self,data_path):\n",
    "\n",
    "        self.data_file = h5py.File(data_path)                                  #Gets the data path of the hash file\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.data_file)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "\n",
    "        index += 1                                                               #Increment index\n",
    "        video = self.data_file['video_'+str(index)]                              #Retrieve video according to the index\n",
    "        feature = np.array(video['feature'][:])                                  #Retrieve the features\n",
    "        label = np.array(video['label'][:])                                      #Retrieve the labels\n",
    "\n",
    "        return feature,label,index\n",
    "\n",
    "def get_loader(path, batch_size=5):\n",
    "\n",
    "    dataset = DatasetMaker(path)\n",
    "    train_dataset, test_dataset = train_test_split(dataset, test_size = 0.2)    #Splits dataset where 80% is trained and 20% is tested\n",
    "    train_loader = DataGenerator(train_dataset)                                 #Feeds dataset to data generator\n",
    "\n",
    "    return train_loader, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "'''\n",
    "This part of the code is for setting up basic configurations.\n",
    "\n",
    "**kwargs allows you to pass keyworded variable length of arguments to a function. \n",
    "You should use **kwargs if you want to handle named arguments in a function.\n",
    "'''\n",
    "class Config():\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "\n",
    "        self.data_path = 'fcsn_tvsum.h5'\n",
    "        self.save_dir = 'save_dir'\n",
    "        self.score_dir = 'score_dir'\n",
    "        self.n_epochs = 5                       #Set number of epochs\n",
    "        self.batch_size = 5                     #Set batch size\n",
    "\n",
    "        for a,b in kwargs.items():\n",
    "            setattr(self,a,b)\n",
    "\n",
    "    def __repr__(self):\n",
    "\n",
    "        config_str = 'Configurations\\n' + pprint.pformat(self.__dict__)\n",
    "\n",
    "        return config_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This part of the code includes the main encoder-decoder model.\n",
    "'''\n",
    "class BuildModel():\n",
    "\n",
    "    def __init__(self, config = None, train_loader = None, test_dataset = None):\n",
    "\n",
    "        #Initialization\n",
    "        self.config = config\n",
    "        self.train_loader = train_loader\n",
    "        self.test_dataset = test_dataset\n",
    "\n",
    "        if not os.path.exists(self.config.score_dir):\n",
    "            os.mkdir(self.config.score_dir)             #Makes score directory, if it doesn't exist\n",
    "\n",
    "        if not os.path.exists(self.config.save_dir):\n",
    "            os.mkdir(self.config.save_dir)              #Makes save directory, if it doesn't exist\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        encoder_inputs = Input(shape = (320, 1024))     #Reshape the input array in-place by assigning a tuple of array dimensions to it\n",
    "\n",
    "        '''\n",
    "        The encoder utilizes bidirectional LSTM.\n",
    "        Bidirectional wrapper creates two copies of given layer, forward_layer and backward_layer.\n",
    "        The output of an LSTM cell or layer of cells is called the hidden state. We have 128 hidden states in LSTM. \n",
    "        Moreover, by setting the return_sequences attribute to True when defining the LSTM layer, It is possible \n",
    "        to access the hidden state output for each input time step. Each LSTM cell retains an internal state that \n",
    "        is not output, called the cell state, or c. Keras provides the return_state argument to the LSTM layer that \n",
    "        will provide access to the hidden state output (state_h) and the cell state (state_c).\n",
    "        '''\n",
    "        encoder_BidirectionalLSTM = Bidirectional(LSTM(128, return_sequences = True, return_state = True))\n",
    "        encoder_out, fh, fc, bh, bc = encoder_BidirectionalLSTM(encoder_inputs)\n",
    "        sh = Concatenate()([fh, bh])\n",
    "        ch = Concatenate()([fc, bc])\n",
    "        encoder_states = [sh, ch]\n",
    "\n",
    "        '''\n",
    "        The decoder utilizes LSTM.\n",
    "        Here we have 256 hidden states.\n",
    "        The encoder-decoder mechanism measures the importance of each frame.\n",
    "        '''\n",
    "        decoder_LSTM = LSTM(256, return_sequences = True)\n",
    "        decoder_out = decoder_LSTM(encoder_out, initial_state = encoder_states)\n",
    "\n",
    "        '''\n",
    "        \n",
    "        The core idea  of the attention layer is each time the model predicts an output word, \n",
    "        it only uses parts of the input where the most relevant information is concentrated \n",
    "        instead of the entire sequence. \n",
    "        '''\n",
    "        attn_layer = Attention(name=\"Attention_Layer\")\n",
    "        attn_out =  attn_layer([encoder_out, decoder_out])\n",
    "\n",
    "        #Concatenates the output of the attention layer and decoder\n",
    "        decoder_concat_input = Concatenate(axis = -1, name = 'concat_layer')([decoder_out, attn_out])\n",
    "\n",
    "        '''\n",
    "        We use the TimeDistributed layer to process the output from the LSTM hidden layer.\n",
    "        TimeDistributed layer applies the same layer to several inputs and produces one \n",
    "        output per input to get the result in time.The softmax function provides \n",
    "        a normalised result at each time step.\n",
    "        '''\n",
    "        dense = TimeDistributed(Dense(1, activation = 'softmax'))\n",
    "        decoder_pred = dense(decoder_concat_input)\n",
    "\n",
    "        model = Model(inputs = encoder_inputs, outputs = decoder_pred)\n",
    "\n",
    "        '''\n",
    "        An optimizer is one of the two arguments required for compiling a Keras model\n",
    "        The Adaptive Moment Estimation is an algorithm for optimization technique for \n",
    "        gradient descent. The method is really efficient when working with large problem \n",
    "        involving a lot of data or parameters. It requires less memory and is efficient. \n",
    "        Intuitively, it is a combination of the gradient descent with momentum\n",
    "        algorithm and the RMSP algorithm.\n",
    "\n",
    "        learning_rate is a Tensor, floating point value, or a schedule that is a \n",
    "        tf.keras.optimizers.schedules.LearningRateSchedule, or a callable that takes no \n",
    "        arguments and returns the actual value to use.\n",
    "        '''\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=0.15)\n",
    "\n",
    "        model.compile(loss = 'binary_crossentropy', optimizer = opt, metrics = ['accuracy'])    #Compliling the model\n",
    "        model.summary()\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        #For evaluating reults for every epoch\n",
    "        t = trange(self.config.n_epochs, desc = 'Epoch', ncols = 90)\n",
    "        for epoch_i in t:\n",
    "\n",
    "            model.fit(self.train_loader)\n",
    "\n",
    "            ckpt_path = self.config.save_dir + '/epoch-{}.ckpt'.format(epoch_i)     #Saving the output of every epoch\n",
    "            tqdm.write(\"Save parameters at {}\".format(ckpt_path))\n",
    "            model.save_weights(ckpt_path)                                           #Saving weights\n",
    "            self.evaluate(epoch_i)\n",
    "\n",
    "    def evaluate(self, epoch_i):\n",
    "\n",
    "        out_dict = {}\n",
    "        eval_arr = []\n",
    "        table = PrettyTable()                                                       #Formatting the table\n",
    "        table.title = 'Evaluation Result of epoch {}'.format(epoch_i)               #Saving evaluation results for every epoch\n",
    "        table.field_names = ['ID', 'Precision', 'Recall', 'F-Score']\n",
    "        table.float_format = '1.5'\n",
    "\n",
    "        with h5py.File(self.config.data_path) as data_file:\n",
    "            for feature, label, index in tqdm(self.test_dataset, desc = 'Evaluate', ncols = 90, leave = False):\n",
    "\n",
    "                pred_score = self.model.predict(feature.reshape(-1,320,1024))\n",
    "                video_info = data_file['video_'+str(index)]\n",
    "                pred_score, pred_selected, pred_summary = eval.select_keyshots(video_info, pred_score)\n",
    "                true_summary_arr = video_info['user_summary'][:]\n",
    "                eval_res = [eval.eval_metrics(pred_summary, true_summary) for true_summary in true_summary_arr]\n",
    "                eval_res = np.mean(eval_res, axis = 0).tolist()\n",
    "\n",
    "                eval_arr.append(eval_res)\n",
    "                table.add_row([index] + eval_res)\n",
    "\n",
    "                out_dict[str(index)] = {\n",
    "                'pred_score' : pred_score,\n",
    "                'pred_selected' : pred_selected,\n",
    "                'pred_summary' : pred_summary\n",
    "                }\n",
    "\n",
    "        score_save_path = self.config.score_dir + '/epoch-{}.json'.format(epoch_i)      #Saving scores in the score directory\n",
    "        with open(score_save_path,'w') as f:\n",
    "            tqdm.write('Save score at {}'.format(str(score_save_path)))\n",
    "            json.dump(out_dict,f)\n",
    "        eval_mean = np.mean(eval_arr, axis = 0).tolist()\n",
    "        table.add_row(['mean'] + eval_mean)\n",
    "        tqdm.write(str(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fq/0p9vc1m94752qt15lmbkg_c40000gn/T/ipykernel_8696/2362700362.py:42: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  self.data_file = h5py.File(data_path)\n",
      "2022-02-06 13:36:22.315489: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-06 13:36:22.343540: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fba7e531ea0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-02-06 13:36:22.343555: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "Epoch:   0%|                                                        | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 320, 1024)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   [(None, 320, 256), ( 1180672     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256)          0           bidirectional[0][1]              \n",
      "                                                                 bidirectional[0][3]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           bidirectional[0][2]              \n",
      "                                                                 bidirectional[0][4]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 320, 256)     525312      bidirectional[0][0]              \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Attention_Layer (Attention)     (None, 320, 256)     0           bidirectional[0][0]              \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, 320, 512)     0           lstm_1[0][0]                     \n",
      "                                                                 Attention_Layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 320, 1)       513         concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,706,497\n",
      "Trainable params: 1,706,497\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "8/8 [==============================] - 3s 434ms/step - loss: 12.4389 - accuracy: 0.1843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                        | 0/5 [00:07<?, ?it/s]/var/folders/fq/0p9vc1m94752qt15lmbkg_c40000gn/T/ipykernel_8696/3161885467.py:64: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  with h5py.File(self.config.data_path) as data_file:\n",
      "\n",
      "Evaluate:   0%|                                                    | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save parameters at save_dir/epoch-0.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate:  10%|████▍                                       | 1/10 [00:00<00:08,  1.06it/s]\u001b[A\n",
      "Evaluate:  20%|████████▊                                   | 2/10 [00:01<00:05,  1.38it/s]\u001b[A\n",
      "Evaluate:  30%|█████████████▏                              | 3/10 [00:01<00:03,  1.77it/s]\u001b[A\n",
      "Evaluate:  40%|█████████████████▌                          | 4/10 [00:01<00:02,  2.34it/s]\u001b[A\n",
      "Evaluate:  50%|██████████████████████                      | 5/10 [00:01<00:01,  3.01it/s]\u001b[A\n",
      "Evaluate:  60%|██████████████████████████▍                 | 6/10 [00:01<00:01,  3.78it/s]\u001b[A\n",
      "Evaluate:  70%|██████████████████████████████▊             | 7/10 [00:01<00:00,  4.05it/s]\u001b[A\n",
      "Evaluate:  80%|███████████████████████████████████▏        | 8/10 [00:01<00:00,  4.91it/s]\u001b[A\n",
      "Evaluate:  90%|███████████████████████████████████████▌    | 9/10 [00:02<00:00,  4.24it/s]\u001b[A\n",
      "Epoch:  20%|█████████▌                                      | 1/5 [00:10<00:41, 10.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save score at score_dir/epoch-0.json\n",
      "+--------------------------------------+\n",
      "|     Evaluation Result of epoch 0     |\n",
      "+------+-----------+---------+---------+\n",
      "|  ID  | Precision |  Recall | F-Score |\n",
      "+------+-----------+---------+---------+\n",
      "|  25  |  0.46979  | 0.46678 | 0.46828 |\n",
      "|  39  |  0.51981  | 0.52043 | 0.52010 |\n",
      "|  6   |  0.60172  | 0.59447 | 0.59807 |\n",
      "|  38  |  0.51379  | 0.51647 | 0.51504 |\n",
      "|  34  |  0.57371  | 0.55339 | 0.56334 |\n",
      "|  15  |  0.47622  | 0.47649 | 0.47633 |\n",
      "|  8   |  0.45424  | 0.45046 | 0.45234 |\n",
      "|  35  |  0.62108  | 0.61829 | 0.61966 |\n",
      "|  12  |  0.62471  | 0.61559 | 0.62012 |\n",
      "|  5   |  0.63819  | 0.64740 | 0.64241 |\n",
      "| mean |  0.54933  | 0.54598 | 0.54757 |\n",
      "+------+-----------+---------+---------+\n",
      "8/8 [==============================] - 4s 459ms/step - loss: 12.4389 - accuracy: 0.1843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|█████████▌                                      | 1/5 [00:14<00:41, 10.41s/it]\n",
      "Evaluate:   0%|                                                    | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save parameters at save_dir/epoch-1.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate:  10%|████▍                                       | 1/10 [00:00<00:01,  7.29it/s]\u001b[A\n",
      "Evaluate:  30%|█████████████▏                              | 3/10 [00:00<00:00,  7.08it/s]\u001b[A\n",
      "Evaluate:  50%|██████████████████████                      | 5/10 [00:00<00:00,  7.72it/s]\u001b[A\n",
      "Evaluate:  60%|██████████████████████████▍                 | 6/10 [00:00<00:00,  7.83it/s]\u001b[A\n",
      "Evaluate:  70%|██████████████████████████████▊             | 7/10 [00:00<00:00,  6.57it/s]\u001b[A\n",
      "Evaluate:  80%|███████████████████████████████████▏        | 8/10 [00:01<00:00,  6.96it/s]\u001b[A\n",
      "Evaluate:  90%|███████████████████████████████████████▌    | 9/10 [00:01<00:00,  4.96it/s]\u001b[A\n",
      "Epoch:  40%|███████████████████▏                            | 2/5 [00:16<00:27,  9.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save score at score_dir/epoch-1.json\n",
      "+--------------------------------------+\n",
      "|     Evaluation Result of epoch 1     |\n",
      "+------+-----------+---------+---------+\n",
      "|  ID  | Precision |  Recall | F-Score |\n",
      "+------+-----------+---------+---------+\n",
      "|  25  |  0.46979  | 0.46678 | 0.46828 |\n",
      "|  39  |  0.51981  | 0.52043 | 0.52010 |\n",
      "|  6   |  0.60172  | 0.59447 | 0.59807 |\n",
      "|  38  |  0.51379  | 0.51647 | 0.51504 |\n",
      "|  34  |  0.57371  | 0.55339 | 0.56334 |\n",
      "|  15  |  0.47622  | 0.47649 | 0.47633 |\n",
      "|  8   |  0.45424  | 0.45046 | 0.45234 |\n",
      "|  35  |  0.62108  | 0.61829 | 0.61966 |\n",
      "|  12  |  0.62471  | 0.61559 | 0.62012 |\n",
      "|  5   |  0.63819  | 0.64740 | 0.64241 |\n",
      "| mean |  0.54933  | 0.54598 | 0.54757 |\n",
      "+------+-----------+---------+---------+\n",
      "8/8 [==============================] - 4s 508ms/step - loss: 12.4389 - accuracy: 0.1843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|███████████████████▏                            | 2/5 [00:21<00:27,  9.09s/it]\n",
      "Evaluate:   0%|                                                    | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save parameters at save_dir/epoch-2.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate:  10%|████▍                                       | 1/10 [00:00<00:01,  6.31it/s]\u001b[A\n",
      "Evaluate:  20%|████████▊                                   | 2/10 [00:00<00:01,  6.89it/s]\u001b[A\n",
      "Evaluate:  30%|█████████████▏                              | 3/10 [00:00<00:01,  5.52it/s]\u001b[A\n",
      "Evaluate:  50%|██████████████████████                      | 5/10 [00:00<00:00,  6.51it/s]\u001b[A\n",
      "Evaluate:  60%|██████████████████████████▍                 | 6/10 [00:00<00:00,  7.18it/s]\u001b[A\n",
      "Evaluate:  70%|██████████████████████████████▊             | 7/10 [00:01<00:00,  6.29it/s]\u001b[A\n",
      "Evaluate:  80%|███████████████████████████████████▏        | 8/10 [00:01<00:00,  7.07it/s]\u001b[A\n",
      "Evaluate:  90%|███████████████████████████████████████▌    | 9/10 [00:01<00:00,  5.21it/s]\u001b[A\n",
      "Epoch:  60%|████████████████████████████▊                   | 3/5 [00:22<00:16,  8.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save score at score_dir/epoch-2.json\n",
      "+--------------------------------------+\n",
      "|     Evaluation Result of epoch 2     |\n",
      "+------+-----------+---------+---------+\n",
      "|  ID  | Precision |  Recall | F-Score |\n",
      "+------+-----------+---------+---------+\n",
      "|  25  |  0.46979  | 0.46678 | 0.46828 |\n",
      "|  39  |  0.51981  | 0.52043 | 0.52010 |\n",
      "|  6   |  0.60172  | 0.59447 | 0.59807 |\n",
      "|  38  |  0.51379  | 0.51647 | 0.51504 |\n",
      "|  34  |  0.57371  | 0.55339 | 0.56334 |\n",
      "|  15  |  0.47622  | 0.47649 | 0.47633 |\n",
      "|  8   |  0.45424  | 0.45046 | 0.45234 |\n",
      "|  35  |  0.62108  | 0.61829 | 0.61966 |\n",
      "|  12  |  0.62471  | 0.61559 | 0.62012 |\n",
      "|  5   |  0.63819  | 0.64740 | 0.64241 |\n",
      "| mean |  0.54933  | 0.54598 | 0.54757 |\n",
      "+------+-----------+---------+---------+\n",
      "8/8 [==============================] - 3s 429ms/step - loss: 12.4389 - accuracy: 0.1843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|████████████████████████████▊                   | 3/5 [00:26<00:16,  8.28s/it]\n",
      "Evaluate:   0%|                                                    | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save parameters at save_dir/epoch-3.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate:  10%|████▍                                       | 1/10 [00:00<00:01,  6.86it/s]\u001b[A\n",
      "Evaluate:  20%|████████▊                                   | 2/10 [00:00<00:01,  7.35it/s]\u001b[A\n",
      "Evaluate:  30%|█████████████▏                              | 3/10 [00:00<00:01,  6.35it/s]\u001b[A\n",
      "Evaluate:  50%|██████████████████████                      | 5/10 [00:00<00:00,  7.20it/s]\u001b[A\n",
      "Evaluate:  70%|██████████████████████████████▊             | 7/10 [00:00<00:00,  7.09it/s]\u001b[A\n",
      "Evaluate:  90%|███████████████████████████████████████▌    | 9/10 [00:01<00:00,  6.35it/s]\u001b[A\n",
      "Epoch:  80%|██████████████████████████████████████▍         | 4/5 [00:28<00:07,  7.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save score at score_dir/epoch-3.json\n",
      "+--------------------------------------+\n",
      "|     Evaluation Result of epoch 3     |\n",
      "+------+-----------+---------+---------+\n",
      "|  ID  | Precision |  Recall | F-Score |\n",
      "+------+-----------+---------+---------+\n",
      "|  25  |  0.46979  | 0.46678 | 0.46828 |\n",
      "|  39  |  0.51981  | 0.52043 | 0.52010 |\n",
      "|  6   |  0.60172  | 0.59447 | 0.59807 |\n",
      "|  38  |  0.51379  | 0.51647 | 0.51504 |\n",
      "|  34  |  0.57371  | 0.55339 | 0.56334 |\n",
      "|  15  |  0.47622  | 0.47649 | 0.47633 |\n",
      "|  8   |  0.45424  | 0.45046 | 0.45234 |\n",
      "|  35  |  0.62108  | 0.61829 | 0.61966 |\n",
      "|  12  |  0.62471  | 0.61559 | 0.62012 |\n",
      "|  5   |  0.63819  | 0.64740 | 0.64241 |\n",
      "| mean |  0.54933  | 0.54598 | 0.54757 |\n",
      "+------+-----------+---------+---------+\n",
      "8/8 [==============================] - 3s 435ms/step - loss: 12.4389 - accuracy: 0.1843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|██████████████████████████████████████▍         | 4/5 [00:32<00:07,  7.48s/it]\n",
      "Evaluate:   0%|                                                    | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save parameters at save_dir/epoch-4.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluate:  10%|████▍                                       | 1/10 [00:00<00:01,  7.26it/s]\u001b[A\n",
      "Evaluate:  30%|█████████████▏                              | 3/10 [00:00<00:01,  6.93it/s]\u001b[A\n",
      "Evaluate:  50%|██████████████████████                      | 5/10 [00:00<00:00,  7.77it/s]\u001b[A\n",
      "Evaluate:  70%|██████████████████████████████▊             | 7/10 [00:00<00:00,  7.44it/s]\u001b[A\n",
      "Evaluate:  90%|███████████████████████████████████████▌    | 9/10 [00:01<00:00,  6.51it/s]\u001b[A\n",
      "Evaluate: 100%|███████████████████████████████████████████| 10/10 [00:01<00:00,  6.90it/s]\u001b[A\n",
      "Epoch: 100%|████████████████████████████████████████████████| 5/5 [00:34<00:00,  6.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save score at score_dir/epoch-4.json\n",
      "+--------------------------------------+\n",
      "|     Evaluation Result of epoch 4     |\n",
      "+------+-----------+---------+---------+\n",
      "|  ID  | Precision |  Recall | F-Score |\n",
      "+------+-----------+---------+---------+\n",
      "|  25  |  0.46979  | 0.46678 | 0.46828 |\n",
      "|  39  |  0.51981  | 0.52043 | 0.52010 |\n",
      "|  6   |  0.60172  | 0.59447 | 0.59807 |\n",
      "|  38  |  0.51379  | 0.51647 | 0.51504 |\n",
      "|  34  |  0.57371  | 0.55339 | 0.56334 |\n",
      "|  15  |  0.47622  | 0.47649 | 0.47633 |\n",
      "|  8   |  0.45424  | 0.45046 | 0.45234 |\n",
      "|  35  |  0.62108  | 0.61829 | 0.61966 |\n",
      "|  12  |  0.62471  | 0.61559 | 0.62012 |\n",
      "|  5   |  0.63819  | 0.64740 | 0.64241 |\n",
      "| mean |  0.54933  | 0.54598 | 0.54757 |\n",
      "+------+-----------+---------+---------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading the dataset and training the model\n",
    "train_config = Config()\n",
    "train_loader, test_dataset = get_loader(train_config.data_path, batch_size = train_config.batch_size)\n",
    "builder = BuildModel(train_config, train_loader, test_dataset)\n",
    "builder.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fq/0p9vc1m94752qt15lmbkg_c40000gn/T/ipykernel_8696/148203453.py:7: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  f_data = h5py.File(h5_path)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This part of the code allows us to use our custom input\n",
    "on the created model and generate a video summary.\n",
    "'''\n",
    "#Initialization\n",
    "h5_path = 'fcsn_tvsum.h5'\n",
    "json_path = 'score_dir/epoch-4.json'\n",
    "data_root = 'input.mp4'\n",
    "save_dir = 'Results'\n",
    "\n",
    "video_dir = os.path.join(data_root)\n",
    "f_data = h5py.File(h5_path)\n",
    "with open(json_path) as f:\n",
    "    json_dict = json.load(f)\n",
    "    ids = json_dict.keys()\n",
    "\n",
    "#Using change points and scores for selecting frames\n",
    "def get_keys(id):\n",
    "    video_info = f_data['video_' + id]\n",
    "    video_path = os.path.join(video_dir)\n",
    "    cps = video_info['change_points'][()]\n",
    "    pred_score = json_dict[id]['pred_score']\n",
    "    pred_selected = json_dict[id]['pred_selected']\n",
    "\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    success, frame = video.read()\n",
    "    while success:\n",
    "        frames.append(frame)\n",
    "        success, frame = video.read()\n",
    "    frames = np.array(frames)\n",
    "    keyshots = []\n",
    "    for sel in pred_selected:\n",
    "        for i in range(cps[sel][0], cps[sel][1]):\n",
    "            keyshots.append(frames[i])\n",
    "    keyshots = np.array(keyshots)\n",
    "\n",
    "    write_path = os.path.join(save_dir,'summary.avi')                   #Saves the output as 'summary.avi' in the 'Results' folder\n",
    "    video_writer = cv2.VideoWriter(write_path, cv2.VideoWriter_fourcc(*'XVID'), 24, keyshots.shape[2:0:-1])\n",
    "    for frame in keyshots:\n",
    "        video_writer.write(frame)\n",
    "    video_writer.release()\n",
    "\n",
    "#Function for generating the summary\n",
    "def gen_summary():\n",
    "    if not os.path.exists(save_dir):                                    #Making the 'Results' directory\n",
    "        os.mkdir(save_dir)\n",
    "\n",
    "    for id in ids:\n",
    "        get_keys(id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 6113 is out of bounds for axis 0 with size 5939",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mswitch_backend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124magg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgen_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mgen_summary\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(save_dir)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ids:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m#os.mkdir(os.path.join(save_dir, id))\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     \u001b[43mget_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mget_keys\u001b[0;34m(id)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sel \u001b[38;5;129;01min\u001b[39;00m pred_selected:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cps[sel][\u001b[38;5;241m0\u001b[39m], cps[sel][\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m---> 29\u001b[0m         keyshots\u001b[38;5;241m.\u001b[39mappend(\u001b[43mframes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     30\u001b[0m keyshots \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(keyshots)\n\u001b[1;32m     32\u001b[0m write_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary.avi\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 6113 is out of bounds for axis 0 with size 5939"
     ]
    }
   ],
   "source": [
    "plt.switch_backend('agg')\n",
    "gen_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
